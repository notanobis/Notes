Ex.
- Digit recognition, approximate propability but not aprroximate result of prediction
- image processing (10% video 20% audio tolerance)

increase performance by decreasing (not needed) accuracy
- circuit simplification
- algorithmic approximation


DNN -> high accuracy , but high performance needs
(DNN accelerators )
accorate multipliers (replace) with approximate MAC units
0.6 error--> not good for deep [[Neural network]] 
Retrain the models for the particular errors--> for lower energy we have higher accuracy

Problem: if we cannot retrain?
Mitigate errors through statistics into the [[Perceptrons]] equation
Averege error
error variance
small accurate adder in mac to calculate the error + additional line of macs
(no retraining)



